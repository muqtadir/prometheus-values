global:
  resolve_timeout: 5m
  smtp_from: "AKS Platform-DEVQA Alerts<aks-qa-alertmanager@sephora.com>"
  smtp_smarthost: azre1-smtp-lower.sephoraus.com:25
  smtp_require_tls: false
route:
  group_by: ['alertname']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 1d
  receiver: 'default'
  routes:
# Match for Monitoring namespace
  - receiver : 'monitoring-namespace'
    match_re:
      namespace: ^(monitoring)$
      prometheus: ^(monitoring/prometheus-operator-prometheus)$
    group_by: [app, alertname]
    continue: false
# below blackbox-probe-failed-ne is for network team refer to connectivity-probe.yml
# if you are changing any thing in this job
  - receiver : 'blackbox-probe-failed-ne'
    match_re:
      alertname: ^(ProbeFailed|DNSLatencyIncreased)$
    group_by: [cluster, alertname]
    continue: false

templates:
- '/etc/alertmanager/config/seph-email.tmpl'

  # routes:
  # - receiver: 'pagerduty'
  #   group_wait: 10s
  #   match:
  #     severity: critical
  # - receiver: 'dev'
  #   group_wait: 10s
  #   match:
  #     severity: warning
receivers:
- name: 'default'
  email_configs:
  - to: 'mcp_engineering@sephora.com'
    send_resolved: true
    headers:
       Subject: '{{ template "email.default.subject" . }}| default'
- name : 'monitoring-namespace'
  email_configs:
  - to: 'mcp_engineering@sephora.com'
    send_resolved: true
    headers:
       Subject: '{{ template "email.default.subject" . }}| monitoring'
- name : 'blackbox-probe-failed-ne'
  email_configs:
  - to: 'tom.tu@sephora.com, network-engineering@sephora.com, mcp_engineering@sephora.com, NOC-Network@sephora.com'
    send_resolved: true
    headers:
       Subject: '{{ template "email.default.subject" . }}| Cross Cluster Probe Failed'
inhibit_rules:
# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
- source_match:
    severity: 'critical'
  target_match:
    severity: 'warning'
# Apply inhibition if the alertname is the same.
# CAUTION:
#   If all label names listed in `equal` are missing
#   from both the source and target alerts,
#   the inhibition rule will apply!
  equal: ['alertname']
- target_match:
     alertname: 'KubeHpaMaxedOut'
  equal: ['prometheus']
- target_match:
     alertname: 'Watchdog'
  equal: ['prometheus']
- target_match:
     alertname: 'KubeSchedulerDown'
  equal: ['prometheus']
- target_match:
     alertname: 'KubeControllerManagerDown'
  equal: ['prometheus']
- target_match:
     alertname: 'KubeJobCompletion'
- target_match:
     alertname: 'CPUThrottlingHigh'
  equal: ['prometheus']
